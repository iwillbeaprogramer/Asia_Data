{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf_V2\\lib\\site-packages\\keras\\datasets\\reuters.py:85: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf_V2\\lib\\site-packages\\keras\\datasets\\reuters.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982,)\n",
      "(2246,)\n",
      "(8982,)\n",
      "(2246,)\n",
      "(8982, 100)\n",
      "(2246, 100)\n",
      "(8982, 46)\n",
      "(2246, 46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_V2\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/20\n",
      "8982/8982 [==============================] - 77s 9ms/step - loss: 2.1819 - accuracy: 0.4545 - val_loss: 2.0015 - val_accuracy: 0.4996\n",
      "Epoch 2/20\n",
      "8982/8982 [==============================] - 77s 9ms/step - loss: 1.8234 - accuracy: 0.5343 - val_loss: 1.7358 - val_accuracy: 0.5574\n",
      "Epoch 3/20\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 1.5930 - accuracy: 0.6010 - val_loss: 1.4674 - val_accuracy: 0.6340\n",
      "Epoch 4/20\n",
      "8982/8982 [==============================] - 84s 9ms/step - loss: 1.3219 - accuracy: 0.6696 - val_loss: 1.3645 - val_accuracy: 0.6625\n",
      "Epoch 5/20\n",
      "8982/8982 [==============================] - 85s 9ms/step - loss: 1.1842 - accuracy: 0.7041 - val_loss: 1.2504 - val_accuracy: 0.6937\n",
      "Epoch 6/20\n",
      "8982/8982 [==============================] - 80s 9ms/step - loss: 1.0737 - accuracy: 0.7321 - val_loss: 1.2263 - val_accuracy: 0.6995\n",
      "Epoch 7/20\n",
      "8982/8982 [==============================] - 80s 9ms/step - loss: 0.9850 - accuracy: 0.7496 - val_loss: 1.1595 - val_accuracy: 0.7088\n",
      "Epoch 8/20\n",
      "8982/8982 [==============================] - 85s 9ms/step - loss: 0.8948 - accuracy: 0.7786 - val_loss: 1.1429 - val_accuracy: 0.7240\n",
      "Epoch 9/20\n",
      "8982/8982 [==============================] - 82s 9ms/step - loss: 0.8157 - accuracy: 0.7953 - val_loss: 1.1296 - val_accuracy: 0.7253\n",
      "Epoch 10/20\n",
      "8982/8982 [==============================] - 82s 9ms/step - loss: 0.7387 - accuracy: 0.8134 - val_loss: 1.1602 - val_accuracy: 0.7226\n",
      "Epoch 11/20\n",
      "8982/8982 [==============================] - 83s 9ms/step - loss: 0.6778 - accuracy: 0.8297 - val_loss: 1.1582 - val_accuracy: 0.7208\n",
      "Epoch 12/20\n",
      "8982/8982 [==============================] - 91s 10ms/step - loss: 0.6140 - accuracy: 0.8456 - val_loss: 1.1934 - val_accuracy: 0.7302\n",
      "Epoch 13/20\n",
      "8982/8982 [==============================] - 85s 9ms/step - loss: 0.5520 - accuracy: 0.8654 - val_loss: 1.2228 - val_accuracy: 0.7257\n",
      "Epoch 14/20\n",
      "8982/8982 [==============================] - 85s 9ms/step - loss: 0.5051 - accuracy: 0.8753 - val_loss: 1.2806 - val_accuracy: 0.7182\n",
      "Epoch 15/20\n",
      "8982/8982 [==============================] - 97s 11ms/step - loss: 0.4656 - accuracy: 0.8857 - val_loss: 1.3036 - val_accuracy: 0.7137\n",
      "Epoch 16/20\n",
      "8982/8982 [==============================] - 90s 10ms/step - loss: 0.4160 - accuracy: 0.8968 - val_loss: 1.3445 - val_accuracy: 0.7191\n",
      "Epoch 17/20\n",
      "8982/8982 [==============================] - 89s 10ms/step - loss: 0.3832 - accuracy: 0.9029 - val_loss: 1.3641 - val_accuracy: 0.7146\n",
      "Epoch 18/20\n",
      "8982/8982 [==============================] - 89s 10ms/step - loss: 0.3398 - accuracy: 0.9118 - val_loss: 1.4519 - val_accuracy: 0.7199\n",
      "Epoch 19/20\n",
      "8982/8982 [==============================] - 93s 10ms/step - loss: 0.3100 - accuracy: 0.9204 - val_loss: 1.4568 - val_accuracy: 0.7257\n",
      "Epoch 20/20\n",
      "8982/8982 [==============================] - 85s 9ms/step - loss: 0.2812 - accuracy: 0.9245 - val_loss: 1.5422 - val_accuracy: 0.7128\n",
      "2246/2246 [==============================] - 3s 1ms/step\n",
      "\n",
      " Accuracy : 0.7128\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "(x_train,y_train),(x_test,y_test) = reuters.load_data(num_words=1000,test_split=0.2)\n",
    "\n",
    "import numpy as np\n",
    "category = np.max(y_train)+1\n",
    "# print(category,' 카테고리')\n",
    "# print(len(x_train),'학습용 뉴스 기사')\n",
    "# print(len(x_test),'테스트용 뉴스 기사')\n",
    "# print(x_train[0])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding,LSTM\n",
    "x_train = pad_sequences(x_train,maxlen=100)\n",
    "x_test = pad_sequences(x_test,maxlen=100)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(1000,100))\n",
    "model.add(LSTM(100,activation='tanh'))\n",
    "model.add(Dense(46,activation = 'softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history = model.fit(x_train,y_train,batch_size=10,epochs=20,validation_data=(x_test,y_test))\n",
    "print(\"\\n Accuracy : %.4f\"%(model.evaluate(x_test,y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding,LSTM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = reuters.load_data(num_words=1000,test_split = 0.2)\n",
    "\n",
    "\n",
    "x_train = pad_sequences(x_train,100)\n",
    "x_test = pad_sequences(x_test,100)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(1000,100))\n",
    "model.add(LSTM(100,activation = 'tanh'))\n",
    "model.add(Dense(46,activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "history = model.fit(x_train,y_train,epochs = 20, batch_size = 128,verbose = 1,validation_data = (x_test,y_test))\n",
    "\n",
    "print(\"\\n Accuracy : {}\".format(model.evaluate(x_test,y_test)[1]))\n",
    "\n",
    "y_valloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "x_len = np.arange(len(y_valloss))\n",
    "plt.plot(x_len,y_valloss,'.',c = 'red',label = 'Testset_loss')\n",
    "plt.plot(x_len,y_loss,'.',c='blue',label = 'Trainset_loss')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
